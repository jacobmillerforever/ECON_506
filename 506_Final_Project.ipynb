{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdr69Fg+Xlas15o9c72I/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobmillerforever/ECON_506/blob/main/506_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction & Setup"
      ],
      "metadata": {
        "id": "kegfoQH7dxYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fredapi\n",
        "!pip install investpy"
      ],
      "metadata": {
        "id": "zimnwBagdHqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "from fredapi import Fred\n",
        "import investpy"
      ],
      "metadata": {
        "id": "7IStQ_96dMOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection & Preparation"
      ],
      "metadata": {
        "id": "lenAt87od0vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ticker_data(ticker_dict, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Fetches data for multiple tickers and creates a DataFrame for each with\n",
        "    single-index columns named as Ticker_ColumnName (e.g., SPY_Close)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    ticker_dict : dict\n",
        "        Dictionary with display names as keys and ticker symbols as values\n",
        "    start_date : str\n",
        "        Start date in format 'YYYY-MM-DD'\n",
        "    end_date : str\n",
        "        End date in format 'YYYY-MM-DD'\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary with display names as keys and their respective DataFrames as values\n",
        "    \"\"\"\n",
        "    ticker_dataframes = {}\n",
        "\n",
        "    for display_name, ticker_symbol in ticker_dict.items():\n",
        "        # Fetch data for current ticker\n",
        "        data = yf.download(ticker_symbol, start=start_date, end=end_date, progress=False)\n",
        "\n",
        "        # Handle multi-index columns if present\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            # Flatten the multi-index columns to single index\n",
        "            data.columns = [f\"{ticker_symbol}_{col[0]}\" for col in data.columns]\n",
        "        else:\n",
        "            # If not multi-index, still rename columns to match pattern\n",
        "            data.columns = [f\"{ticker_symbol}_{col}\" for col in data.columns]\n",
        "\n",
        "        # Store the DataFrame in the dictionary with display name as key\n",
        "        ticker_dataframes[display_name] = data\n",
        "\n",
        "    return ticker_dataframes\n",
        "\n",
        "tickers = {\n",
        "    # Global Indices\n",
        "    'Nikkei 225 (Japan)': '^N225',\n",
        "    'Hang Seng (Hong Kong)': '^HSI',\n",
        "    'SSE Composite (China)': '000001.SS',\n",
        "    'ASX 200 (Australia)': '^AXJO',\n",
        "    'DAX (Germany)': '^GDAXI',\n",
        "    'FTSE 100 (UK)': '^FTSE',\n",
        "    'CAC 40 (France)': '^FCHI',\n",
        "    'Euro Stoxx 50 (EU)': '^STOXX50E',\n",
        "    'SPY (US)': 'SPY',\n",
        "\n",
        "\n",
        "    # Volatility Indices\n",
        "    'VIX (US)': '^VIX',\n",
        "    'VIX Brazil': '^VXEWZ',\n",
        "    'DAX Volatility': '^VDAX',\n",
        "\n",
        "    # Currency Pairs\n",
        "    'US Dollar Index': 'DX-Y.NYB',\n",
        "    'EUR/USD': 'EURUSD=X',\n",
        "    'JPY/USD': 'JPY=X',\n",
        "    'CNY/USD': 'CNY=X',\n",
        "\n",
        "    # Commodities\n",
        "    'Gold': 'GC=F',\n",
        "    'Crude Oil': 'CL=F',\n",
        "    'Silver': 'SI=F',\n",
        "    'Corn': 'ZC=F',\n",
        "    'Copper': 'HG=F'\n",
        "}\n",
        "\n",
        "start_date = '2000-01-01'\n",
        "end_date = dt.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "# Get individual DataFrames for each ticker\n",
        "ticker_data = get_ticker_data(tickers, start_date, end_date)\n",
        "\n",
        "# Display the first few rows and column names for each DataFrame\n",
        "for display_name, df in ticker_data.items():\n",
        "    print(f\"\\n{display_name} DataFrame:\")\n",
        "    print(f\"Column names: {df.columns.tolist()}\")\n",
        "    print(df.head())"
      ],
      "metadata": {
        "id": "gl-IDnFda5K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fred_data(api_key, series_list, start_date='2000-01-01', end_date=None):\n",
        "    \"\"\"\n",
        "    Fetches data for multiple FRED series at the highest available frequency\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    api_key : str\n",
        "        Your FRED API key\n",
        "    series_list : list\n",
        "        List of FRED series IDs as strings\n",
        "    start_date : str, optional\n",
        "        Start date in format 'YYYY-MM-DD', defaults to '2000-01-01'\n",
        "    end_date : str, optional\n",
        "        End date in format 'YYYY-MM-DD', defaults to current date\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary with series IDs as keys and their respective DataFrames as values\n",
        "    dict\n",
        "        Dictionary with series IDs as keys and the frequency used as values\n",
        "    \"\"\"\n",
        "    # Initialize FRED API connection\n",
        "    fred = Fred(api_key=api_key)\n",
        "\n",
        "    # Set end date to current date if not provided\n",
        "    if end_date is None:\n",
        "        end_date = dt.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "    # Convert start and end dates to datetime objects\n",
        "    start_dt = dt.datetime.strptime(start_date, '%Y-%m-%d')\n",
        "    end_dt = dt.datetime.strptime(end_date, '%Y-%m-%d')\n",
        "\n",
        "    # Initialize dictionaries to store DataFrames and frequencies\n",
        "    fred_dataframes = {}\n",
        "    fred_frequencies = {}\n",
        "\n",
        "    # Frequency hierarchy from highest to lowest resolution\n",
        "    # Not all series support all frequencies\n",
        "    frequency_hierarchy = ['d', 'w', 'bw', 'm', 'q', 'sa', 'a']\n",
        "\n",
        "    # Process each series ID\n",
        "    for series_id in series_list:\n",
        "        # Try frequencies in order from highest to lowest resolution\n",
        "        for freq in frequency_hierarchy:\n",
        "            try:\n",
        "                # Get data for current series with current frequency\n",
        "                data = fred.get_series(series_id, start_dt, end_dt, frequency=freq)\n",
        "\n",
        "                # If successful and data is not empty, convert to DataFrame\n",
        "                if not data.empty:\n",
        "                    # Convert Series to DataFrame\n",
        "                    df = pd.DataFrame(data)\n",
        "                    df.columns = [f\"{series_id}_value\"]\n",
        "\n",
        "                    # Add to dictionaries\n",
        "                    fred_dataframes[series_id] = df\n",
        "                    fred_frequencies[series_id] = freq\n",
        "\n",
        "                    print(f\"Successfully fetched data for {series_id} with frequency '{freq}'\")\n",
        "                    # Break out of frequency loop once we've found a working frequency\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"No data found for {series_id} with frequency '{freq}'\")\n",
        "            except Exception as e:\n",
        "                # If this frequency doesn't work, try the next one\n",
        "                print(f\"Could not fetch {series_id} with frequency '{freq}': {str(e)}\")\n",
        "\n",
        "        # Check if we were able to fetch this series with any frequency\n",
        "        if series_id not in fred_dataframes:\n",
        "            print(f\"Failed to fetch data for {series_id} with any available frequency\")\n",
        "\n",
        "    return fred_dataframes, fred_frequencies\n",
        "\n",
        "from google.colab import userdata\n",
        "fred_api = '8b000b950d5841b5b7e35ebbcacedaea'\n",
        "\n",
        "fred_series = [\n",
        "    'DFF',           # Federal Funds Rate\n",
        "    'T10Y2Y',        # 10-Year minus 2-Year Treasury Spread\n",
        "    'CPIAUCSL',      # Consumer Price Index\n",
        "    'UNRATE',        # Unemployment Rate\n",
        "    'STLFSI',        # St. Louis Fed Financial Stress Index\n",
        "    'M2SL',          # M2 Money Supply\n",
        "    'USSLIND',       # US Leading Index\n",
        "    'BAMLH0A0HYM2',  # High Yield Spread\n",
        "    'GS5',           # 5-Year Treasury Rate\n",
        "    'GS30',          # 30-Year Treasury Rate\n",
        "    'BAMLC0A0CM'     # Corporate Bond Spread\n",
        "]\n",
        "\n",
        "fred_data = get_fred_data(fred_api, fred_series)"
      ],
      "metadata": {
        "id": "j3dC6dlDcMT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calendar_df = investpy.economic_calendar(\n",
        "      from_date='01/01/2000',\n",
        "      to_date='31/12/2025',\n",
        "      countries=['united states'],\n",
        "      categories=['monetary policy', 'inflation', 'employment'],\n",
        "      importances=['high']\n",
        ")\n",
        "\n",
        "calendar_df = calendar_df[~calendar_df['importance'].isna()].reset_index(drop=True)\n",
        "calendar_df.tail()\n"
      ],
      "metadata": {
        "id": "2IBARAw-_XD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "9iuXIf8id7Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "def eda_indices_dict(ticker_data_dict):\n",
        "    \"\"\"\n",
        "    Perform EDA on dictionary of DataFrame indices from yfinance\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    ticker_data_dict : dict\n",
        "        Dictionary with ticker symbols as keys and their DataFrames as values\n",
        "    \"\"\"\n",
        "    print(\"=== EDA for Market Indices ===\\n\")\n",
        "\n",
        "    # Summary statistics for each index\n",
        "    for display_name, df in ticker_data_dict.items():\n",
        "        print(f\"\\n--- {display_name} ---\")\n",
        "        print(f\"Data range: {df.index.min().date()} to {df.index.max().date()}\")\n",
        "        print(f\"Number of trading days: {len(df)}\")\n",
        "\n",
        "        # Handle missing data\n",
        "        missing_data = df.isnull().sum()\n",
        "        if missing_data.any():\n",
        "            print(\"\\nMissing values:\")\n",
        "            print(missing_data[missing_data > 0])\n",
        "\n",
        "        # Calculate returns\n",
        "        close_col = [col for col in df.columns if 'Close' in col][0]\n",
        "        returns = df[close_col].pct_change()\n",
        "\n",
        "        # Summary statistics for close prices\n",
        "        print(f\"\\nClose price statistics:\")\n",
        "        print(f\"Mean: {df[close_col].mean():.2f}\")\n",
        "        print(f\"Std Dev: {df[close_col].std():.2f}\")\n",
        "        print(f\"Min: {df[close_col].min():.2f}\")\n",
        "        print(f\"Max: {df[close_col].max():.2f}\")\n",
        "\n",
        "        # Return statistics\n",
        "        print(f\"\\nDaily return statistics:\")\n",
        "        print(f\"Mean daily return: {returns.mean():.4%}\")\n",
        "        print(f\"Std dev of returns: {returns.std():.4%}\")\n",
        "        print(f\"Sharpe ratio (annualized): {(returns.mean() / returns.std() * np.sqrt(252)):.2f}\")\n",
        "        print(f\"Skewness: {returns.skew():.2f}\")\n",
        "        print(f\"Kurtosis: {returns.kurtosis():.2f}\")\n",
        "\n",
        "        # Plot closing prices and returns\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "        # Price chart\n",
        "        ax1.plot(df.index, df[close_col])\n",
        "        ax1.set_title(f\"{display_name} - Closing Prices\")\n",
        "        ax1.set_ylabel(\"Price\")\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Returns histogram\n",
        "        ax2.hist(returns.dropna(), bins=100, alpha=0.75, color='blue', edgecolor='black')\n",
        "        ax2.set_title(f\"{display_name} - Return Distribution\")\n",
        "        ax2.set_xlabel(\"Daily Returns\")\n",
        "        ax2.set_ylabel(\"Frequency\")\n",
        "        ax2.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Correlation analysis between indices\n",
        "    print(\"\\n=== Correlation Analysis ===\")\n",
        "    close_prices_dict = {}\n",
        "    for display_name, df in ticker_data_dict.items():\n",
        "        close_col = [col for col in df.columns if 'Close' in col][0]\n",
        "        close_prices_dict[display_name] = df[close_col]\n",
        "\n",
        "    close_prices_df = pd.DataFrame(close_prices_dict)\n",
        "    correlation_matrix = close_prices_df.pct_change().corr()\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
        "    plt.title(\"Correlation Matrix of Daily Returns\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "eda_indices_dict(ticker_data)\n"
      ],
      "metadata": {
        "id": "3frCFPBBH2ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eda_fred_data(fred_data_tuple):\n",
        "    \"\"\"\n",
        "    Perform EDA on FRED API data\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    fred_data_tuple : tuple\n",
        "        Tuple containing (dataframes_dict, frequencies_dict)\n",
        "    \"\"\"\n",
        "    dataframes_dict, frequencies_dict = fred_data_tuple\n",
        "\n",
        "    print(\"=== EDA for FRED Economic Indicators ===\\n\")\n",
        "\n",
        "    # Summary for each FRED series\n",
        "    for series_id, df in dataframes_dict.items():\n",
        "        frequency = frequencies_dict[series_id]\n",
        "        print(f\"\\n--- {series_id} (Frequency: {frequency}) ---\")\n",
        "        print(f\"Data range: {df.index.min().date()} to {df.index.max().date()}\")\n",
        "        print(f\"Number of observations: {len(df)}\")\n",
        "\n",
        "        # Handle missing data\n",
        "        missing_data = df.isnull().sum()\n",
        "        if missing_data.any():\n",
        "            print(\"\\nMissing values:\")\n",
        "            print(missing_data[missing_data > 0])\n",
        "\n",
        "        # Summary statistics\n",
        "        value_col = df.columns[0]\n",
        "        print(f\"\\nSummary statistics:\")\n",
        "        print(f\"Mean: {df[value_col].mean():.2f}\")\n",
        "        print(f\"Std Dev: {df[value_col].std():.2f}\")\n",
        "        print(f\"Min: {df[value_col].min():.2f}\")\n",
        "        print(f\"Max: {df[value_col].max():.2f}\")\n",
        "\n",
        "        # Calculate percent change based on frequency\n",
        "        if frequency == 'd':\n",
        "            pct_change = df[value_col].pct_change(fill_method=None)\n",
        "            change_label = 'Daily % Change'\n",
        "        elif frequency == 'w':\n",
        "            pct_change = df[value_col].pct_change(fill_method=None)\n",
        "            change_label = 'Weekly % Change'\n",
        "        elif frequency == 'm':\n",
        "            pct_change = df[value_col].pct_change(fill_method=None)\n",
        "            change_label = 'Monthly % Change'\n",
        "        else:\n",
        "            pct_change = df[value_col].pct_change(fill_method=None)\n",
        "            change_label = '% Change'\n",
        "\n",
        "        # Remove infinite and NaN values\n",
        "        pct_change_clean = pct_change.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "        if len(pct_change_clean) > 0:\n",
        "            print(f\"\\n{change_label} statistics:\")\n",
        "            print(f\"Mean: {pct_change_clean.mean():.4%}\")\n",
        "            print(f\"Std Dev: {pct_change_clean.std():.4%}\")\n",
        "\n",
        "            # Plot time series and change distribution\n",
        "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "            # Time series plot\n",
        "            ax1.plot(df.index, df[value_col])\n",
        "            ax1.set_title(f\"{series_id} - Time Series\")\n",
        "            ax1.set_ylabel(\"Value\")\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "\n",
        "            # Change distribution\n",
        "            try:\n",
        "                ax2.hist(pct_change_clean, bins=50, alpha=0.75, color='green', edgecolor='black')\n",
        "                ax2.set_title(f\"{series_id} - {change_label} Distribution\")\n",
        "                ax2.set_xlabel(change_label)\n",
        "                ax2.set_ylabel(\"Frequency\")\n",
        "                ax2.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: Could not create histogram for {series_id}: {str(e)}\")\n",
        "                ax2.text(0.5, 0.5, 'Histogram not available\\ndue to data issues',\n",
        "                         ha='center', va='center', transform=ax2.transAxes)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"Warning: No valid {change_label} data available for {series_id}\")\n",
        "\n",
        "    # Combine all FRED data for correlation analysis\n",
        "    print(\"\\n=== Cross-Series Analysis ===\")\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    for series_id, df in dataframes_dict.items():\n",
        "        # Resample all series to monthly frequency for comparison\n",
        "        if frequencies_dict[series_id] == 'd':\n",
        "            resampled = df.resample('M').last()\n",
        "        elif frequencies_dict[series_id] == 'w':\n",
        "            resampled = df.resample('M').last()\n",
        "        else:\n",
        "            resampled = df\n",
        "\n",
        "        combined_df[series_id] = resampled[resampled.columns[0]]\n",
        "\n",
        "    # Calculate correlation matrix with handling for NaN values\n",
        "    combined_pct_change = combined_df.pct_change(fill_method=None)\n",
        "    combined_pct_change_clean = combined_pct_change.replace([np.inf, -np.inf], np.nan)\n",
        "    correlation_matrix = combined_pct_change_clean.corr()\n",
        "\n",
        "    if not correlation_matrix.empty:\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
        "        plt.title(\"Correlation Matrix of Economic Indicators (Monthly % Changes)\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Warning: Not enough valid data to create correlation matrix\")\n",
        "\n",
        "eda_fred_data((fred_data[0], fred_data[1]))\n"
      ],
      "metadata": {
        "id": "-TMHwNHFH6_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "def eda_indices_dict(ticker_data_dict):\n",
        "    \"\"\"\n",
        "    Perform EDA on dictionary of DataFrame indices from yfinance\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    ticker_data_dict : dict\n",
        "        Dictionary with ticker symbols as keys and their DataFrames as values\n",
        "    \"\"\"\n",
        "    print(\"=== EDA for Market Indices ===\\n\")\n",
        "\n",
        "    # Find the common start date and individual start dates\n",
        "    all_start_dates = {}\n",
        "    all_end_dates = {}\n",
        "    for display_name, df in ticker_data_dict.items():\n",
        "        all_start_dates[display_name] = df.index.min()\n",
        "        all_end_dates[display_name] = df.index.max()\n",
        "\n",
        "    common_start_date = max(all_start_dates.values())\n",
        "    common_end_date = min(all_end_dates.values())\n",
        "\n",
        "    print(f\"Common data period (all indices available): {common_start_date.date()} to {common_end_date.date()}\")\n",
        "    print(f\"Total common trading days: {sum(1 for d in pd.date_range(common_start_date, common_end_date, freq='B'))}\")\n",
        "\n",
        "    # Summary statistics for each index\n",
        "    for display_name, df in ticker_data_dict.items():\n",
        "        print(f\"\\n--- {display_name} ---\")\n",
        "        print(f\"Data range: {df.index.min().date()} to {df.index.max().date()}\")\n",
        "        print(f\"Number of trading days: {len(df)}\")\n",
        "\n",
        "        # Check data availability\n",
        "        if df.index.min() > pd.Timestamp('2000-01-01'):\n",
        "            print(f\"⚠️ Data starts after 2000: {df.index.min().date()}\")\n",
        "\n",
        "        # Handle missing data\n",
        "        missing_data = df.isnull().sum()\n",
        "        if missing_data.any():\n",
        "            print(\"\\nMissing values:\")\n",
        "            print(missing_data[missing_data > 0])\n",
        "\n",
        "        # Calculate returns\n",
        "        close_col = [col for col in df.columns if 'Close' in col][0]\n",
        "        returns = df[close_col].pct_change()\n",
        "\n",
        "        # Summary statistics for close prices\n",
        "        print(f\"\\nClose price statistics:\")\n",
        "        print(f\"Mean: {df[close_col].mean():.2f}\")\n",
        "        print(f\"Std Dev: {df[close_col].std():.2f}\")\n",
        "        print(f\"Min: {df[close_col].min():.2f}\")\n",
        "        print(f\"Max: {df[close_col].max():.2f}\")\n",
        "\n",
        "        # Return statistics\n",
        "        print(f\"\\nDaily return statistics:\")\n",
        "        print(f\"Mean daily return: {returns.mean():.4%}\")\n",
        "        print(f\"Std dev of returns: {returns.std():.4%}\")\n",
        "        print(f\"Sharpe ratio (annualized): {(returns.mean() / returns.std() * np.sqrt(252)):.2f}\")\n",
        "        print(f\"Skewness: {returns.skew():.2f}\")\n",
        "        print(f\"Kurtosis: {returns.kurtosis():.2f}\")\n",
        "\n",
        "        # Plot closing prices and returns\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "        # Price chart\n",
        "        ax1.plot(df.index, df[close_col])\n",
        "        ax1.set_title(f\"{display_name} - Closing Prices\")\n",
        "        ax1.set_ylabel(\"Price\")\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Returns histogram\n",
        "        ax2.hist(returns.dropna(), bins=100, alpha=0.75, color='blue', edgecolor='black')\n",
        "        ax2.set_title(f\"{display_name} - Return Distribution\")\n",
        "        ax2.set_xlabel(\"Daily Returns\")\n",
        "        ax2.set_ylabel(\"Frequency\")\n",
        "        ax2.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Correlation analysis between indices (using common period)\n",
        "    print(\"\\n=== Correlation Analysis ===\")\n",
        "    close_prices_dict = {}\n",
        "    for display_name, df in ticker_data_dict.items():\n",
        "        close_col = [col for col in df.columns if 'Close' in col][0]\n",
        "        close_prices_dict[display_name] = df[close_col]\n",
        "\n",
        "    close_prices_df = pd.DataFrame(close_prices_dict)\n",
        "\n",
        "    # Common period correlation\n",
        "    common_period_df = close_prices_df.loc[common_start_date:common_end_date]\n",
        "    correlation_matrix_common = common_period_df.pct_change().corr()\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(correlation_matrix_common, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
        "    plt.title(f\"Correlation Matrix of Daily Returns (Common Period: {common_start_date.date()} to {common_end_date.date()})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # All available data correlation (with missing values)\n",
        "    correlation_matrix_all = close_prices_df.pct_change().corr()\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(correlation_matrix_all, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
        "    plt.title(\"Correlation Matrix of Daily Returns (All Available Data)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Data availability timeline\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for i, (display_name, df) in enumerate(ticker_data_dict.items()):\n",
        "        plt.barh(i, (df.index.max() - df.index.min()).days,\n",
        "                left=(df.index.min() - pd.Timestamp('2000-01-01')).days,\n",
        "                height=0.6, label=f\"{display_name}: {df.index.min().date()} to {df.index.max().date()}\")\n",
        "\n",
        "    plt.yticks(range(len(ticker_data_dict)), list(ticker_data_dict.keys()))\n",
        "    plt.xlabel(\"Days since 2000-01-01\")\n",
        "    plt.title(\"Data Availability Timeline for Each Index\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def eda_fred_data(fred_data_tuple):\n",
        "    \"\"\"\n",
        "    Perform EDA on FRED API data\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    fred_data_tuple : tuple\n",
        "        Tuple containing (dataframes_dict, frequencies_dict)\n",
        "    \"\"\"\n",
        "    dataframes_dict, frequencies_dict = fred_data_tuple\n",
        "\n",
        "    print(\"=== EDA for FRED Economic Indicators ===\\n\")\n",
        "\n",
        "    # Summary for each FRED series\n",
        "    for series_id, df in dataframes_dict.items():\n",
        "        frequency = frequencies_dict[series_id]\n",
        "        print(f\"\\n--- {series_id} (Frequency: {frequency}) ---\")\n",
        "        print(f\"Data range: {df.index.min().date()} to {df.index.max().date()}\")\n",
        "        print(f\"Number of observations: {len(df)}\")\n",
        "\n",
        "        # Handle missing data\n",
        "        missing_data = df.isnull().sum()\n",
        "        if missing_data.any():\n",
        "            print(\"\\nMissing values:\")\n",
        "            print(missing_data[missing_data > 0])\n",
        "\n",
        "        # Summary statistics\n",
        "        value_col = df.columns[0]\n",
        "        print(f\"\\nSummary statistics:\")\n",
        "        print(f\"Mean: {df[value_col].mean():.2f}\")\n",
        "        print(f\"Std Dev: {df[value_col].std():.2f}\")\n",
        "        print(f\"Min: {df[value_col].min():.2f}\")\n",
        "        print(f\"Max: {df[value_col].max():.2f}\")\n",
        "\n",
        "        # Calculate percent change based on frequency\n",
        "        if frequency == 'd':\n",
        "            pct_change = df[value_col].pct_change(fill_method=None)\n",
        "            change_label = 'Daily % Change'\n",
        "        elif frequency == 'w':\n",
        "            pct_change = df[value_col].pct_change(fill_method=None)\n",
        "            change_label = 'Weekly % Change'\n",
        "        elif frequency == 'm':\n",
        "            pct_change = df[value_col].pct_change(fill_method=None)\n",
        "            change_label = 'Monthly % Change'\n",
        "        else:\n",
        "            pct_change = df[value_col].pct_change(fill_method=None)\n",
        "            change_label = '% Change'\n",
        "\n",
        "        # Remove infinite and NaN values\n",
        "        pct_change_clean = pct_change.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "        if len(pct_change_clean) > 0:\n",
        "            print(f\"\\n{change_label} statistics:\")\n",
        "            print(f\"Mean: {pct_change_clean.mean():.4%}\")\n",
        "            print(f\"Std Dev: {pct_change_clean.std():.4%}\")\n",
        "\n",
        "            # Plot time series and change distribution\n",
        "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "            # Time series plot\n",
        "            ax1.plot(df.index, df[value_col])\n",
        "            ax1.set_title(f\"{series_id} - Time Series\")\n",
        "            ax1.set_ylabel(\"Value\")\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "\n",
        "            # Change distribution\n",
        "            try:\n",
        "                ax2.hist(pct_change_clean, bins=50, alpha=0.75, color='green', edgecolor='black')\n",
        "                ax2.set_title(f\"{series_id} - {change_label} Distribution\")\n",
        "                ax2.set_xlabel(change_label)\n",
        "                ax2.set_ylabel(\"Frequency\")\n",
        "                ax2.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: Could not create histogram for {series_id}: {str(e)}\")\n",
        "                ax2.text(0.5, 0.5, 'Histogram not available\\ndue to data issues',\n",
        "                         ha='center', va='center', transform=ax2.transAxes)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"Warning: No valid {change_label} data available for {series_id}\")\n",
        "\n",
        "    # Combine all FRED data for correlation analysis\n",
        "    print(\"\\n=== Cross-Series Analysis ===\")\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    for series_id, df in dataframes_dict.items():\n",
        "        # Resample all series to monthly frequency for comparison\n",
        "        if frequencies_dict[series_id] == 'd':\n",
        "            resampled = df.resample('M').last()\n",
        "        elif frequencies_dict[series_id] == 'w':\n",
        "            resampled = df.resample('M').last()\n",
        "        else:\n",
        "            resampled = df\n",
        "\n",
        "        combined_df[series_id] = resampled[resampled.columns[0]]\n",
        "\n",
        "    # Calculate correlation matrix with handling for NaN values\n",
        "    combined_pct_change = combined_df.pct_change(fill_method=None)\n",
        "    combined_pct_change_clean = combined_pct_change.replace([np.inf, -np.inf], np.nan)\n",
        "    correlation_matrix = combined_pct_change_clean.corr()\n",
        "\n",
        "    if not correlation_matrix.empty:\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
        "        plt.title(\"Correlation Matrix of Economic Indicators (Monthly % Changes)\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Warning: Not enough valid data to create correlation matrix\")\n",
        "\n",
        "def eda_calendar_data(calendar_df):\n",
        "    \"\"\"\n",
        "    Perform EDA on economic calendar data\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    calendar_df : pandas.DataFrame\n",
        "        DataFrame containing economic calendar data\n",
        "    \"\"\"\n",
        "    print(\"=== EDA for Economic Calendar ===\\n\")\n",
        "\n",
        "    # Basic info\n",
        "    print(f\"Date range: {calendar_df['date'].min()} to {calendar_df['date'].max()}\")\n",
        "    print(f\"Total number of events: {len(calendar_df)}\")\n",
        "\n",
        "    # Convert date column to datetime - handle potential type issues\n",
        "    if calendar_df['date'].dtype != 'datetime64[ns]':\n",
        "        try:\n",
        "            # Try converting to string first if necessary\n",
        "            calendar_df['date'] = calendar_df['date'].astype(str)\n",
        "            calendar_df['date'] = pd.to_datetime(calendar_df['date'], format='%d/%m/%Y')\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not convert date column: {e}\")\n",
        "            # Try alternative conversion\n",
        "            try:\n",
        "                calendar_df['date'] = pd.to_datetime(calendar_df['date'])\n",
        "            except Exception as e2:\n",
        "                print(f\"Error: Unable to convert date column: {e2}\")\n",
        "                return\n",
        "\n",
        "    # Extract year and month for analysis\n",
        "    calendar_df['year'] = calendar_df['date'].dt.year\n",
        "    calendar_df['month'] = calendar_df['date'].dt.month\n",
        "    calendar_df['weekday'] = calendar_df['date'].dt.dayofweek\n",
        "\n",
        "    # Events by type\n",
        "    print(\"\\n--- Event Categories ---\")\n",
        "    event_types = calendar_df['event'].str.extract(r'(.+?)\\s*(?:\\(|\\s*$)')[0].value_counts()\n",
        "    print(event_types.head(15))\n",
        "\n",
        "    # Events by year\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    yearly_events = calendar_df.groupby('year').size()\n",
        "    yearly_events.plot(kind='bar', alpha=0.75, color='blue', edgecolor='black')\n",
        "    plt.title(\"Number of Economic Events by Year\")\n",
        "    plt.xlabel(\"Year\")\n",
        "    plt.ylabel(\"Number of Events\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Events by month\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    monthly_events = calendar_df.groupby('month').size()\n",
        "    monthly_events.plot(kind='bar', alpha=0.75, color='green', edgecolor='black')\n",
        "    plt.title(\"Number of Economic Events by Month\")\n",
        "    plt.xlabel(\"Month\")\n",
        "    plt.ylabel(\"Number of Events\")\n",
        "    plt.xticks(range(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Events by weekday\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    weekday_events = calendar_df.groupby('weekday').size()\n",
        "    weekday_events.plot(kind='bar', alpha=0.75, color='orange', edgecolor='black')\n",
        "    plt.title(\"Number of Economic Events by Weekday\")\n",
        "    plt.xlabel(\"Weekday\")\n",
        "    plt.ylabel(\"Number of Events\")\n",
        "    plt.xticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Time of day analysis\n",
        "    try:\n",
        "        calendar_df['hour'] = pd.to_datetime(calendar_df['time'].astype(str), format='%H:%M').dt.hour\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        hourly_events = calendar_df.groupby('hour').size()\n",
        "        hourly_events.plot(kind='bar', alpha=0.75, color='purple', edgecolor='black')\n",
        "        plt.title(\"Number of Economic Events by Hour of Day\")\n",
        "        plt.xlabel(\"Hour\")\n",
        "        plt.ylabel(\"Number of Events\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not analyze time of day: {e}\")\n",
        "\n",
        "    # # Event importance\n",
        "    # print(\"\\n--- Event Importance ---\")\n",
        "    # importance_counts = calendar_df['importance'].value_counts()\n",
        "    # print(importance_counts)\n",
        "\n",
        "    # Create a heatmap of events by month and year\n",
        "    pivot_table = calendar_df.pivot_table(\n",
        "        values='id',\n",
        "        index='year',\n",
        "        columns='month',\n",
        "        aggfunc='count',\n",
        "        fill_value=0\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(pivot_table, cmap='YlOrRd', annot=True, fmt='d')\n",
        "    plt.title(\"Event Count Heatmap by Year and Month\")\n",
        "    plt.xlabel(\"Month\")\n",
        "    plt.ylabel(\"Year\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Most common event types over time\n",
        "    calendar_df['event_type'] = calendar_df['event'].str.extract(r'(.+?)\\s*(?:\\(|\\s*$)')[0]\n",
        "    top_5_events = event_types.head(5).index\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for event in top_5_events:\n",
        "        event_data = calendar_df[calendar_df['event_type'] == event]\n",
        "        event_by_year = event_data.groupby('year').size()\n",
        "        plt.plot(event_by_year.index, event_by_year.values, marker='o', label=event)\n",
        "\n",
        "    plt.title(\"Top 5 Economic Event Types by Year\")\n",
        "    plt.xlabel(\"Year\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "eda_calendar_data(calendar_df)"
      ],
      "metadata": {
        "id": "0PBXNe6aNQi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "KlRIHTfOeEWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Development"
      ],
      "metadata": {
        "id": "6l5IjaqLeHHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "4ug4MBM5eN85"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dExarGOxd6QP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}